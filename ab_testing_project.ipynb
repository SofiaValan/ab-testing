{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audacity A/B Testing Project\n",
    "\n",
    "## Experiment Overview: Free Trial Screener\n",
    "\n",
    "Udacity is an online course platform specialized in IT sector. At the moment, they want to run an experiment on their website with the goal of improving the course completion rate of their students.\n",
    "\n",
    "### Context\n",
    "\n",
    "Let's take a more in-deepth look to how the Udacity environment is setup before the experiment:\n",
    "\n",
    "* Udacity courses currently have two options on the course overview page: \"Start Free Trial\", and \"Access Course Materials\".\n",
    "* If the student clicks \"Start Free Trial\" button, they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course.\n",
    "* If the student clicks \"Access Course Materials\", they will be able to view the videos and take the quizzes for free, but they will not receive any bonuses, like coaching services or earning the certificate of the course.\n",
    "\n",
    "### Description of the Experiment\n",
    "\n",
    "* In the experiment, Udacity tested a change where if the student clicked \"Start Free Trial\" button, they were asked how much time they had available to devote to the course. \n",
    "* If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. \n",
    "* If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. \n",
    "* At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead.\n",
    "\n",
    "### Hypothesis Testing\n",
    "\n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough timeâ€”without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n",
    "\n",
    "### Unit of Diversion\n",
    "\n",
    "The unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page.\n",
    "\n",
    "## Experiment Design\n",
    "### Metric Choice\n",
    "\n",
    "The invariant metrics are the ones which shouldn't change across the experiment and the control group. These metrics work to perform a sanity check after running the experiment to test if there was any issue on the process.\n",
    "\n",
    "The evaluation metrics are those target metrics that you expect to change across groups and are relevant for the business goals. For each metric, it is defined a $D_{min}$ which marks the minimum change which is practically significant to the business. This figure is provided by Udacity for each of the metrics:\n",
    "\n",
    "#### Invariant Metrics (Sanity Check)\n",
    "\n",
    "For this case, the following metrics will be chosen as invariant metrics:\n",
    "\n",
    "* Number of cookies per course page by day. This metric has been chosen because in this case the number of cookies for each group should remain the same during the experiment. As cookies is our unit of diversion for this experiment, the sample size needs to be the same across both groups. It will be represented by $Cookies$ and it has a $D_{min} = 3,000$.\n",
    "  \n",
    "* Number of clicks in the 'Start Free Trial' button by day. As this click happens before the Free Trial Screener message appears, this metric shouldn't be impacted by the experiment. It should remain with no changes. It will be represented by $Clicks$ and it has a $D_{min} = 240$.\n",
    "  \n",
    "* Click-Through-Probability in the 'Start Free Trial' button by day. This metric is the relationship between the number of clicks on the 'Start Free Trial' button and the number of cookies on page. If these two metrics don't change, the CTP shouldn't change either. It will be represented by $\\frac{Clicks}{Cookies}$ and it has a $D_{min} = 0.01$.\n",
    "\n",
    "#### Evaluation Metrics\n",
    "\n",
    "The metrics that will be used as evaluation metrics are:\n",
    "\n",
    "* Gross Conversion. This metric is the relationship between the number of user IDs to complete the checkout and enroll the free trial divided by unique cookie clicks on the button. It will be represented by $\\frac{User IDs enrolled}{Clicks}$ and it has a $D_{min} = 0.01$.\n",
    "\n",
    "* Retention. This metric is the relationship between the number of user IDs to remain enrolled and make at least one payment divided by unique user IDs to complete the checkout. It will be represented by $\\frac{User IDs paid}{User IDs enrolled}$ and it has a $D_{min} = 0.01$.\n",
    "  \n",
    "* Net Conversion. This metric is the relationship between the number of user IDs to remain enrolled and make at least one payment divided by the number of unique cookie clicks on the button. It will be represented by $\\frac{User IDs paid}{Clicks}$ and it has a $D_{min} = 0.0075$.\n",
    "\n",
    "These three metrics are expected to change because they are measured after the Free Trial Screener message appears. Also, they are relevant for the business because they help to measure the low funnel performance and retention.\n",
    "\n",
    "### Measuring Standard Deviation\n",
    "\n",
    "Udacity provides the following rough estimates for these metrics, probably measured with a daily aggregation. This is the baseline for each of the metrics:\n",
    "\n",
    "* Unique cookies to view course overview page per day: 40,000\n",
    "* Unique cookies to click \"Start free trial\" per day: 3,200\n",
    "* Enrollments per day: 660\n",
    "* Click-through-probability on \"Start free trial\": 0.08\n",
    "* Probability of enrolling, given click (Gross Conversion): 0.20625\n",
    "* Probability of payment, given enroll (Retention): 0.53\n",
    "* Probability of payment, given click (Net Conversion): 0.1093125\n",
    "\n",
    "Now, we will need to calculate the standard deviation for each of the evaluation metrics. This step is very important to test if a metric has a great variability or it is more robust. On one hand, the most variant a metric is, the harder is to get significant results. In the other hand, if the metric is too robust, it is possible it's too insensitive to capture the statistically significant change. \n",
    "\n",
    "Udacity assumes a sample size of 5,000 cookies visiting the course overview page per day. As the previous data is based on baseline numbers, we will need to readjust the metrics to a sample size of 5,000 cookies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the baseline estimates\n",
    "baseline = {\"Total Cookies\":40000, \"Total Clicks\":3200, \"Total Enrollments\":660, \"CTP\":0.08, \"Gross Conversion\":0.20625, \"Retention\":0.53, \"Net Conversion\":0.1093125}\n",
    "\n",
    "# Creating a copy of baseline to add the adjustments\n",
    "sample_adjusted = baseline\n",
    "\n",
    "# Defining the samples\n",
    "n = 40000\n",
    "n_adjusted = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total Cookies': 5000,\n",
       " 'Total Clicks': 400.0,\n",
       " 'Total Enrollments': 82.5,\n",
       " 'CTP': 0.08,\n",
       " 'Gross Conversion': 0.20625,\n",
       " 'Retention': 0.53,\n",
       " 'Net Conversion': 0.1093125}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the estimates from a sample size of 40,000 to 5,000\n",
    "\n",
    "sample_adjusted[\"Total Cookies\"] = 5000\n",
    "sample_adjusted[\"Total Clicks\"] = (n_adjusted * baseline[\"Total Clicks\"] / n)\n",
    "sample_adjusted[\"Total Enrollments\"] = (n_adjusted * baseline[\"Total Enrollments\"] / n)\n",
    "sample_adjusted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our evaluations metrics are probabilities, we can assume all of them have a binomial distribution (or normal, as we have enough data samples). Now, let's calculate the standard deviation based on this with the following formula:\n",
    "\n",
    "$$SD = \\sqrt{\\frac{p'(1-p')}{N}}$$\n",
    "\n",
    "We can do this assumption for the Gross Conversion and the Net Conversion because the unit of diversion is the same that the unit of analysis (metric placed on the denominator). In this case, the unit of diversion is the cookie, as well as the unit of analysis (number of cookies who clicked). We can expect the analytical estimates to be accurate.\n",
    "\n",
    "However, the Retention metric doesn't have the same unit of analysis and unit of diversion. In this case, the unit of diversion is the cookie but the unit of analysis is the user ID. For this reason, the analytical estimates might not match the empirical estimates and it will be worth it to calculate it empirically too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to calculate the standard deviation\n",
    "def sd(p, n):\n",
    "    dic = {}\n",
    "    dic[\"sd\"] = round(np.sqrt((p*(1-p))/n), 4)\n",
    "    return dic['sd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0202\n",
      "0.0549\n",
      "0.0156\n"
     ]
    }
   ],
   "source": [
    "# Let's create three new dictionaries for each metric\n",
    "gross_conversion = {}\n",
    "retention = {}\n",
    "net_conversion = {}\n",
    "\n",
    "# Adding the Dmin data to each dictionary\n",
    "gross_conversion[\"d_min\"] = 0.01\n",
    "retention[\"d_min\"] = 0.01\n",
    "net_conversion[\"d_min\"] = 0.0075\n",
    "\n",
    "# Calculating p and n for each metric\n",
    "gross_conversion[\"p\"] = sample_adjusted[\"Gross Conversion\"]\n",
    "gross_conversion[\"n\"] = sample_adjusted[\"Total Clicks\"]\n",
    "\n",
    "retention[\"p\"] = sample_adjusted[\"Retention\"]\n",
    "retention[\"n\"] = sample_adjusted[\"Total Enrollments\"]\n",
    "\n",
    "net_conversion[\"p\"] = sample_adjusted[\"Net Conversion\"]\n",
    "net_conversion[\"n\"] = sample_adjusted[\"Total Clicks\"]\n",
    "\n",
    "# Using the function created to get the standard deviation\n",
    "print(sd(gross_conversion[\"p\"], gross_conversion['n']))\n",
    "print(sd(retention[\"p\"], retention['n']))\n",
    "print(sd(net_conversion[\"p\"], net_conversion['n']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizing\n",
    "#### Number of Samples vs. Power\n",
    "\n",
    "First of all, we are going to use the formula Evan Miller used on his online calculator to calculate the sample size:\n",
    "\n",
    "$$n = \\frac{Z_{1-\\frac{\\alpha}{2}}Â·sd_{1}+Z_{1-\\beta}Â·sd_{2}}{d^2}$$\n",
    "\n",
    "$$sd_{1} = \\sqrt{2p(1-p)}$$\n",
    "$$sd_{2} = \\sqrt{p(1-p)+(p+d)(1-p-d)}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $p_{1}$ is the baseline conversion rate.\n",
    "* $\\delta$ is the detectable change.\n",
    "* $\\alpha$ is the significance level.\n",
    "* $\\beta$ is the statistical power or practice significance.\n",
    "* $Z_{\\frac{\\alpha}{2}}$ means the z-score from the z table that corresponds to $\\frac{\\alpha}{2}$\n",
    "* $Z_{\\beta}$ means the z-score from the z table that corresponds to $\\beta$\n",
    "\n",
    "During the whole experiment, $\\alpha = 0.05$ and $1-\\beta = 0.20$. The z-score for each of them are $Z_{\\frac{0.05}{2}} = -1.959963985$ and $Z_{\\beta} = -0.841621234$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the sample size\n",
    "def sample_size(p, delta):\n",
    "    if p > 0.5:\n",
    "        p = 1.0 - p\n",
    "    \n",
    "    z_a = 1.959963985\n",
    "    z_b = 0.841621234\n",
    "\n",
    "    sd1 = np.sqrt(2 * p * (1.0 - p))\n",
    "    sd2 = np.sqrt(p * (1.0 - p) + (p + delta) * (1.0 - p - delta))\n",
    "\n",
    "    return round((z_a * sd1 + z_b * sd2) * (z_a * sd1 + z_b * sd2) / (delta * delta), 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gross Conversion\n",
    "\n",
    "For Gross Conversion, we will need at least 25,835 cookies who click in the Free Trial button per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25835.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_conversion['sample_size'] = sample_size(gross_conversion['p'], gross_conversion['d_min'])\n",
    "gross_conversion['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to estimate the number of pageviews needed to achieve those 25,835 cookies per group. To do so, we need to calculate the ratio between clicks and pageviews: $400/5000 = 0.08$. Now, let's divide the sample size we got between this result and multiply it by two, as we have two groups in the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645875.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_conversion['sample_size'] = (gross_conversion['sample_size']/0.08)*2\n",
    "gross_conversion['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would need in total 645,875 pageviews in total counting both groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retention\n",
    "\n",
    "Regarding retention, we will need at least 39,087 users who enrolled per group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39115.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retention['sample_size'] = sample_size(retention['p'], retention['d_min'])\n",
    "retention['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we divide this result by 0.08 to know how many users need to click on the 'Start Free Trial' button and then how many cookies viewed a course overview page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4741212.121212121"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retention['sample_size'] = ((retention['sample_size']/0.08)/gross_conversion['p'])*2\n",
    "retention['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we will need 4,74 million pageviews. However, this number is quite high, as Udacity attracts 40,000 cookies per day. The experiment would need to last 120 days to gather the necessary sample. For these reasons, we drop this metric from the experiment.\n",
    "\n",
    "##### Net Conversion\n",
    "\n",
    "For net conversion, we will need at least 27,413 users who click per group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27413.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_conversion['sample_size'] = sample_size(net_conversion['p'], net_conversion['d_min'])\n",
    "net_conversion['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to calculate how many pageviews we will need by dividing between 0.08. This way, we will need 685,325 pageviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685325.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_conversion['sample_size'] = ((net_conversion['sample_size']/0.08))*2\n",
    "net_conversion['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this number of pageviews is bigger than the one needed for the gross conversion, this is going to be our sample size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration vs. Exposure\n",
    "\n",
    "As we said, we will need 685,325 cookies who viewed the course overview page. If we take the 100% of the traffic, the experiment will take 18 days. However, we prefer the experiment to take one month, so we collect four different weeks of data. This way, we'll be able to see if there is important variations between workdays and weekdays. After taking this decision, the experiment will last 28 days, collecting 24,476 cookies per day. This is around 55% of daily traffic.\n",
    "\n",
    "## Experiment Analysis\n",
    "\n",
    "Now, let's analyze the data once the experiment has been run. First of all, we will create two different dataframes, one for the control group and other for the experiment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0  Sat, Oct 11       7723     687        134.0      70.0\n",
       "1  Sun, Oct 12       9102     779        147.0      70.0\n",
       "2  Mon, Oct 13      10511     909        167.0      95.0\n",
       "3  Tue, Oct 14       9871     836        156.0     105.0\n",
       "4  Wed, Oct 15      10014     837        163.0      64.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = pd.read_excel(\"final_project_results.xlsx\", sheet_name = 'Control')\n",
    "exp = pd.read_excel(\"final_project_results.xlsx\", sheet_name = 'Experiment')\n",
    "con.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "\n",
    "The first step before analyzing the results is performing a sanity check in the invariant metrics. This will help us to define if the experiment was ran as expected. For each of our invariant metrics, we will check if they pass the test or not:\n",
    "\n",
    "* Number of cookies per course page.\n",
    "  \n",
    "* Number of clicks in the 'Start Free Trial' button.\n",
    "  \n",
    "* Click-Through-Probability in the 'Start Free Trial' button.\n",
    "\n",
    "#### Sanity Check for Counts\n",
    "\n",
    "For a count, we should calculate a confidence interval around the fraction of events you expect to be assigned to the control group, and the observed value should be the actual fraction that was assigned to the control group. \n",
    "\n",
    "##### Number of Cookies per Course Page\n",
    "\n",
    "Let's take a look to the total pageviews for each group. If we calculate the total number of pageviews per group, we can see the difference is quite low between groups. However, is this within what we expected? We need to verify that this difference is not statistically significant and was randomly \n",
    "\n",
    "As this invariant metric follows a binomial distribution, we can build a binomial confidence interval. The total sample size here is about 690,203 cookies, which is definitively enough to assume a normal distribution in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pagesviews for control group: 345543 \n",
      "Total number of pageviews for experiment group: 344660\n",
      "The size of the sample is 690203\n"
     ]
    }
   ],
   "source": [
    "# Summing the total number of pageviews for each group\n",
    "con_pages = con['Pageviews'].sum()\n",
    "exp_pages = exp['Pageviews'].sum()\n",
    "print(f\"Total number of pagesviews for control group: {con_pages} \\nTotal number of pageviews for experiment group: {exp_pages}\")\n",
    "\n",
    "# Summing the total sample size\n",
    "total_pages = con_pages + exp_pages\n",
    "print(f\"The size of the sample is {total_pages}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will compute the standard deviation of a binomial distribution with probability 0.5 of success, which I'll assign as control group. \n",
    "\n",
    "Then, we'll multiply the standard deviation by the z-score to get the margin of error. The z-score used in the margin of error for a 95% of confidence interval is 1.96. This can be checked in the z-score tables availables on the Internet.\n",
    "\n",
    "After that, we'll compute a confidence interval around 0.5. If the experiment is set up properly, it's very likely that this observed fraction of successes or cookies in the control group will fall within this confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error for pageviews is 0.0006\n",
      "The margin of error for pageviews is 0.0012\n",
      "The upper confidence interval for pageviews is 0.5012 and the lower confidence interval is 0.4988\n"
     ]
    }
   ],
   "source": [
    "# Calculating the standard error for a normal distribution\n",
    "se_pages = round(np.sqrt((0.5*0.5)/total_pages), 4)\n",
    "print(f\"The standard error for pageviews is {se_pages}\")\n",
    "\n",
    "# Calculating the margin of error\n",
    "me_pages = round(se_pages * 1.96, 4)\n",
    "print(f\"The margin of error for pageviews is {me_pages}\")\n",
    "\n",
    "# Calculating the confidence interval\n",
    "print(f\"The upper confidence interval for pageviews is {0.5+me_pages} and the lower confidence interval is {0.5-me_pages}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the portion of pageviews for the control group to see if it's inside the interval or not. As we can see, 0.5006 is within the confidence interval. This means the difference between the groups is expected, so this metric passes the sanity check correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of pageviews from the total for the control group is 0.5006\n"
     ]
    }
   ],
   "source": [
    "# Calculating the fraction of the control group\n",
    "p_hat_pages = round(con_pages/total_pages, 4)\n",
    "print(f\"The fraction of pageviews from the total for the control group is {p_hat_pages}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Clicks in 'Start Free Trial' Button\n",
    "\n",
    "Let's follow the same approach for the total number of clicks on the 'Start Free Trial' button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of clicks for control group: 28378 \n",
      "Total number of pageviews for experiment group: 28325\n",
      "The size of the sample is 56703\n"
     ]
    }
   ],
   "source": [
    "# Summing the total number of pageviews for each group\n",
    "con_clicks = con['Clicks'].sum()\n",
    "exp_clicks = exp['Clicks'].sum()\n",
    "print(f\"Total number of clicks for control group: {con_clicks} \\nTotal number of pageviews for experiment group: {exp_clicks}\")\n",
    "\n",
    "# Summing the total sample size\n",
    "total_clicks = con_clicks + exp_clicks\n",
    "print(f\"The size of the sample is {total_clicks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error for clicks is 0.0021\n",
      "The margin of error for clicks is 0.0041\n",
      "The upper confidence interval for clicks is 0.5041 and the lower confidence interval is 0.4959\n"
     ]
    }
   ],
   "source": [
    "# Calculating the standard error for a normal distribution\n",
    "se_clicks = round(np.sqrt((0.5*0.5)/total_clicks), 4)\n",
    "print(f\"The standard error for clicks is {se_clicks}\")\n",
    "\n",
    "# Calculating the margin of error\n",
    "me_clicks = round(se_clicks * 1.96, 4)\n",
    "print(f\"The margin of error for clicks is {me_clicks}\")\n",
    "\n",
    "# Calculating the confidence interval\n",
    "print(f\"The upper confidence interval for clicks is {0.5+me_clicks} and the lower confidence interval is {0.5-me_clicks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of clicks from the total for the control group is 0.5005\n"
     ]
    }
   ],
   "source": [
    "# Calculating the fraction of the control group\n",
    "p_hat_clicks = round(con_clicks/total_clicks, 4)\n",
    "print(f\"The fraction of clicks from the total for the control group is {p_hat_clicks}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check for Probabilities & Rates\n",
    "\n",
    "For any other type of metric, we should construct a confidence interval for a difference in proportions, then check whether the difference between group values falls within that confidence level.\n",
    "\n",
    "##### Click-Through-Probability in 'Start Free Trial' Button\n",
    "\n",
    "for the CTP, we want to make sure the proportion of clicks given a pageview is similar in both groups. We'll need to calculate the confidence interval for the difference. We'll start by calculating the pooled probability, that is the total number of clicks in both groups divided by the total number of users.\n",
    "\n",
    "$$p'_{pooled} = \\frac{clicks_{con}+clicks_{exp}}{pages_{con}+pages_{exp}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pooled probability is 0.0822\n"
     ]
    }
   ],
   "source": [
    "# Calculating the pooled probability\n",
    "p_pool = round((total_clicks) / (total_pages), 4)\n",
    "print(f\"The pooled probability is {p_pool}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll calculate the standard error using the following formula:\n",
    "\n",
    "$$SE_{pool} = \\sqrt{p'_{pool}Â·(1-p'_{pool})Â·(\\frac{1}{N_{con}}+\\frac{1}{N_{exp}})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error is 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Calculating the standard error\n",
    "se_pool = round(np.sqrt(p_pool*(1-p_pool)*(1/con_pages+1/exp_pages)),4)\n",
    "print(f\"The standard error is {se_pool}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined the estimated difference as the experimental probability minus the control probability. Let's calculate this difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference for the CTP is 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Calculating the CTP for control and experiment group\n",
    "con_ctp = con_clicks/con_pages\n",
    "exp_ctp = exp_clicks/exp_pages\n",
    "\n",
    "# Calculating difference for the CTP\n",
    "d_hat=round(exp_ctp-con_ctp,4)\n",
    "print(f\"The difference for the CTP is {d_hat}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the margin of error and the confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The margin of error is is 0.0007\n",
      "The upper confidence interval for CTP is 0.0015 and the lower confidence interval is -0.0013\n"
     ]
    }
   ],
   "source": [
    "# Calculating the margin of error\n",
    "me_ctp = round(se_pool * 1.96, 4)\n",
    "print(f\"The margin of error is is {se_pool}\")\n",
    "\n",
    "# Calculating the confidence interval\n",
    "print(f\"The upper confidence interval for CTP is {d_hat+me_ctp} and the lower confidence interval is {d_hat-me_ctp}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 0.0001 is inside our confidence interval, we can say this change in the CTP is not significant and random. So, this metric passes the test too!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "#### Evaluating Practical and Statistical Significance\n",
    "\n",
    "Next, for our evaluation metrics, we will calculate a confidence interval for the difference between the experiment and control groups, and check whether each metric is statistically and/or practically significance. A metric is statistically significant if the confidence interval does not include 0 (that is, you can be confident there was a change), and it is practically significant if the confidence interval does not include the practical significance boundary (that is, you can be confident there is a change that matters to the business.)\n",
    "\n",
    "We can see that for the last 14 days of the experiment, we only collected pageviews and clicks. For this reason, we should remove the last 14 days from the dataset, so we are not counting more pageviews and clicks, so we only keep the completed records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the count clicks from the completed rows\n",
    "con_clicks_test = con[\"Clicks\"].loc[con[\"Enrollments\"].notnull()].sum()\n",
    "exp_clicks_test = exp[\"Clicks\"].loc[exp[\"Enrollments\"].notnull()].sum()\n",
    "\n",
    "# Calculating the count of enrollments and payments\n",
    "con_enroll_test = con[\"Enrollments\"].sum()\n",
    "exp_enroll_test = exp[\"Enrollments\"].sum()\n",
    "con_pay_test = con[\"Payments\"].sum()\n",
    "exp_pay_test = exp[\"Payments\"].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the confidence interval for all the evaluations metrics.\n",
    "\n",
    "##### Gross Conversion\n",
    "\n",
    "First of all, let's calculate the value of the gross conversion for the total experiment in both groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_gc = con_enroll_test/con_clicks_test\n",
    "exp_gc = exp_enroll_test/exp_clicks_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will calculate the pooled probability and the standard pooled error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pooled probability is 0.20860706740369866\n",
      "The standard error is 0.004371675385225936\n"
     ]
    }
   ],
   "source": [
    "# Calculating the pooled probability\n",
    "gc_pooled = (con_enroll_test+exp_enroll_test)/(con_clicks_test+exp_clicks_test)\n",
    "print(f\"The pooled probability is {gc_pooled}\")\n",
    "\n",
    "# Calculating the standard error \n",
    "gc_se_pooled = np.sqrt((gc_pooled)*(1-gc_pooled)*((1/con_clicks_test)+(1/exp_clicks_test)))\n",
    "print(f\"The standard error is {gc_se_pooled}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to estimate the margin of error, the difference and the confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The margin of error is is 0.0086\n",
      "The difference is -0.0206\n",
      "The upper confidence interval is -0.012 and the lower confidence interval is -0.0292\n"
     ]
    }
   ],
   "source": [
    "# Calculating the margin of error\n",
    "gc_me = round(1.96*gc_se_pooled,4)\n",
    "print(f\"The margin of error is is {gc_me}\")\n",
    "\n",
    "# Getting the difference between Gross Conversion in experiment group and control group\n",
    "gc_d = round(exp_gc-con_gc, 4)\n",
    "print(f\"The difference is {gc_d}\")\n",
    "\n",
    "# Calculating the confidence interval\n",
    "print(f\"The upper confidence interval is {gc_d+gc_me} and the lower confidence interval is {gc_d-gc_me}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the zero is not included in the interval [-0.012, -0.0292], we can conclude that the gross conversion has experienced a statistically significant change. Also, we can say there is practical significance because -0.01 is not included in the interval as well. \n",
    "\n",
    "We agreed to have at least 1% of change in this evaluation metric and the new version had -2.06% change in the gross conversion. This means the experiment group experienced a decrease on the gross conversion rate. Then, we can conclude that less people enrolled in the Free Trial after including the pop-up."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Net Conversion\n",
    "\n",
    "First of all, let's calculate the value of the net conversion for the total experiment in both groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_ec = con_pay_test/con_clicks_test\n",
    "exp_ec = exp_pay_test/exp_clicks_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will calculate the pooled probability and the standard pooled error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pooled probability is 0.1151274853124186\n",
      "The standard error is 0.0034341335129324238\n"
     ]
    }
   ],
   "source": [
    "# Calculating the pooled probability\n",
    "ec_pooled = (con_pay_test+exp_pay_test)/(con_clicks_test+exp_clicks_test)\n",
    "print(f\"The pooled probability is {ec_pooled}\")\n",
    "\n",
    "# Calculating the standard error \n",
    "ec_se_pooled = np.sqrt((ec_pooled)*(1-ec_pooled)*((1/con_clicks_test)+(1/exp_clicks_test)))\n",
    "print(f\"The standard error is {ec_se_pooled}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to estimate the margin of error, the difference and the confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The margin of error is is 0.0067\n",
      "The difference is -0.0049\n",
      "The upper confidence interval is 0.0018000000000000004 and the lower confidence interval is -0.0116\n"
     ]
    }
   ],
   "source": [
    "# Calculating the margin of error\n",
    "ec_me = round(1.96*ec_se_pooled,4)\n",
    "print(f\"The margin of error is is {ec_me}\")\n",
    "\n",
    "# Getting the difference between Gross Conversion in experiment group and control group\n",
    "ec_d = round(exp_ec-con_ec, 4)\n",
    "print(f\"The difference is {ec_d}\")\n",
    "\n",
    "# Calculating the confidence interval\n",
    "print(f\"The upper confidence interval is {ec_d+ec_me} and the lower confidence interval is {ec_d-ec_me}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have a change of -0.49%, which is not statistically significant (the 0 is included in the confidence interval) and it is not practically significant (-0.0075 is included in the interval). We needed at least a change of 0.75% to see a practical change, but we only got a 0.49%. We can conclude that we had a decrease in the net conversion after adding the pop-up."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sign Tests\n",
    "\n",
    "Finally, we are going to perform a sign using to see if there is any significant change in the day-by-day data. First of all, we will perform the metrics per day for both experiments and add them to the same dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date_con           37\n",
       "Pageviews_con      37\n",
       "Clicks_con         37\n",
       "Enrollments_con    23\n",
       "Payments_con       23\n",
       "Date_exp           37\n",
       "Pageviews_exp      37\n",
       "Clicks_exp         37\n",
       "Enrollments_exp    23\n",
       "Payments_exp       23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the control and experiment group in the same DataFrame\n",
    "full = con.join(exp, how = 'left', lsuffix=\"_con\",rsuffix=\"_exp\")\n",
    "full.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's remove the incomplete rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date_con           23\n",
       "Pageviews_con      23\n",
       "Clicks_con         23\n",
       "Enrollments_con    23\n",
       "Payments_con       23\n",
       "Date_exp           23\n",
       "Pageviews_exp      23\n",
       "Clicks_exp         23\n",
       "Enrollments_exp    23\n",
       "Payments_exp       23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = full.dropna(axis = 0, how = 'any')\n",
    "full.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the daily Gross Conversion and Net Conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.insert(5, 'GC_con', full['Enrollments_con']/full['Clicks_con'])\n",
    "full.insert(6, 'NC_con', full['Payments_con']/full['Clicks_con'])\n",
    "\n",
    "full.insert(12, 'GC_exp', full['Enrollments_exp']/full['Clicks_exp'])\n",
    "full.insert(13, 'NC_exp', full['Payments_exp']/full['Clicks_exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_con</th>\n",
       "      <th>Pageviews_con</th>\n",
       "      <th>Clicks_con</th>\n",
       "      <th>Enrollments_con</th>\n",
       "      <th>Payments_con</th>\n",
       "      <th>GC_con</th>\n",
       "      <th>NC_con</th>\n",
       "      <th>Date_exp</th>\n",
       "      <th>Pageviews_exp</th>\n",
       "      <th>Clicks_exp</th>\n",
       "      <th>Enrollments_exp</th>\n",
       "      <th>Payments_exp</th>\n",
       "      <th>GC_exp</th>\n",
       "      <th>NC_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.195051</td>\n",
       "      <td>0.101892</td>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7716</td>\n",
       "      <td>686</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.049563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.188703</td>\n",
       "      <td>0.089859</td>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9288</td>\n",
       "      <td>785</td>\n",
       "      <td>116.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.147771</td>\n",
       "      <td>0.115924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.183718</td>\n",
       "      <td>0.104510</td>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10480</td>\n",
       "      <td>884</td>\n",
       "      <td>145.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.164027</td>\n",
       "      <td>0.089367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>0.125598</td>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9867</td>\n",
       "      <td>827</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.166868</td>\n",
       "      <td>0.111245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.194743</td>\n",
       "      <td>0.076464</td>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>0.112981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date_con  Pageviews_con  Clicks_con  Enrollments_con  Payments_con  \\\n",
       "0  Sat, Oct 11           7723         687            134.0          70.0   \n",
       "1  Sun, Oct 12           9102         779            147.0          70.0   \n",
       "2  Mon, Oct 13          10511         909            167.0          95.0   \n",
       "3  Tue, Oct 14           9871         836            156.0         105.0   \n",
       "4  Wed, Oct 15          10014         837            163.0          64.0   \n",
       "\n",
       "     GC_con    NC_con     Date_exp  Pageviews_exp  Clicks_exp  \\\n",
       "0  0.195051  0.101892  Sat, Oct 11           7716         686   \n",
       "1  0.188703  0.089859  Sun, Oct 12           9288         785   \n",
       "2  0.183718  0.104510  Mon, Oct 13          10480         884   \n",
       "3  0.186603  0.125598  Tue, Oct 14           9867         827   \n",
       "4  0.194743  0.076464  Wed, Oct 15           9793         832   \n",
       "\n",
       "   Enrollments_exp  Payments_exp    GC_exp    NC_exp  \n",
       "0            105.0          34.0  0.153061  0.049563  \n",
       "1            116.0          91.0  0.147771  0.115924  \n",
       "2            145.0          79.0  0.164027  0.089367  \n",
       "3            138.0          92.0  0.166868  0.111245  \n",
       "4            140.0          94.0  0.168269  0.112981  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add a 1 when the Gross Conversion is higher in the experiment group than in the control group and 0 in the other case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_con</th>\n",
       "      <th>Pageviews_con</th>\n",
       "      <th>Clicks_con</th>\n",
       "      <th>Enrollments_con</th>\n",
       "      <th>Payments_con</th>\n",
       "      <th>GC_con</th>\n",
       "      <th>NC_con</th>\n",
       "      <th>Date_exp</th>\n",
       "      <th>Pageviews_exp</th>\n",
       "      <th>Clicks_exp</th>\n",
       "      <th>Enrollments_exp</th>\n",
       "      <th>Payments_exp</th>\n",
       "      <th>GC_exp</th>\n",
       "      <th>NC_exp</th>\n",
       "      <th>GC</th>\n",
       "      <th>NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.195051</td>\n",
       "      <td>0.101892</td>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7716</td>\n",
       "      <td>686</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.049563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.188703</td>\n",
       "      <td>0.089859</td>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9288</td>\n",
       "      <td>785</td>\n",
       "      <td>116.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.147771</td>\n",
       "      <td>0.115924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.183718</td>\n",
       "      <td>0.104510</td>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10480</td>\n",
       "      <td>884</td>\n",
       "      <td>145.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.164027</td>\n",
       "      <td>0.089367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>0.125598</td>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9867</td>\n",
       "      <td>827</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.166868</td>\n",
       "      <td>0.111245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.194743</td>\n",
       "      <td>0.076464</td>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>0.112981</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date_con  Pageviews_con  Clicks_con  Enrollments_con  Payments_con  \\\n",
       "0  Sat, Oct 11           7723         687            134.0          70.0   \n",
       "1  Sun, Oct 12           9102         779            147.0          70.0   \n",
       "2  Mon, Oct 13          10511         909            167.0          95.0   \n",
       "3  Tue, Oct 14           9871         836            156.0         105.0   \n",
       "4  Wed, Oct 15          10014         837            163.0          64.0   \n",
       "\n",
       "     GC_con    NC_con     Date_exp  Pageviews_exp  Clicks_exp  \\\n",
       "0  0.195051  0.101892  Sat, Oct 11           7716         686   \n",
       "1  0.188703  0.089859  Sun, Oct 12           9288         785   \n",
       "2  0.183718  0.104510  Mon, Oct 13          10480         884   \n",
       "3  0.186603  0.125598  Tue, Oct 14           9867         827   \n",
       "4  0.194743  0.076464  Wed, Oct 15           9793         832   \n",
       "\n",
       "   Enrollments_exp  Payments_exp    GC_exp    NC_exp  GC  NC  \n",
       "0            105.0          34.0  0.153061  0.049563   0   0  \n",
       "1            116.0          91.0  0.147771  0.115924   0   1  \n",
       "2            145.0          79.0  0.164027  0.089367   0   0  \n",
       "3            138.0          92.0  0.166868  0.111245   0   0  \n",
       "4            140.0          94.0  0.168269  0.112981   0   1  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['GC'] = np.where(full['GC_con']<full['GC_exp'], 1, 0)\n",
    "full['NC'] = np.where(full['NC_con']<full['NC_exp'], 1, 0)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases for GC: 4 \n",
      " Number of cases for NC: 10 \n",
      " Number of total cases: 23\n"
     ]
    }
   ],
   "source": [
    "gc_all = full['GC'][full[\"GC\"] == 1].count()\n",
    "nc_all = full['NC'][full[\"NC\"] == 1].count()\n",
    "n = full['NC'].count()\n",
    "print(\"Number of cases for GC:\", gc_all,'\\n',\n",
    "      \"Number of cases for NC:\", nc_all,'\\n',\n",
    "      \"Number of total cases:\", n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can use an online calculator for the sign test. We only need to add the number of success and the total number of cases and get the p-value for a two-tail test. That's the probability of observing a result at least this extreme by chance.\n",
    "\n",
    "For the Gross Conversion, we have 4 success cases and 23 cases in total. If the probability of success in each trial is 0.05, then the p-value is 0.0026. Since it is less than 0.05, we can conclude the sign test agrees with the hypothesis test: this result was unlikely to come about by chance. So, it's significant.\n",
    "\n",
    "For the Net Conversion, we have 10 success cases and 23 cases in total. If the probability of success in each trial is 0.05, then the p-value is 0.6776. Since it is higher than 0.05, we can conclude the sign test is not significant.\n",
    "\n",
    "We get the same conclusions that in the effect size section of this analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "With the results that we have got, I wouldn't recommend to proceed with the change. We have seen it might have a negative impact in the gross conversion, but not in the net conversion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ace5384e8512bec205467adaaa03d1a59280dc6777c0f016ce91eb37065280f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
