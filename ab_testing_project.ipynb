{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audacity A/B Testing Project\n",
    "\n",
    "## Experiment Overview: Free Trial Screener\n",
    "\n",
    "Udacity is an online course platform specialized in IT sector. At the moment, they want to run an experiment on their website with the goal of improving the course completion rate of their students.\n",
    "\n",
    "### Context\n",
    "\n",
    "Let's take a more in-deepth look to how the Udacity environment is setup before the experiment:\n",
    "\n",
    "* Udacity courses currently have two options on the course overview page: \"Start Free Trial\", and \"Access Course Materials\".\n",
    "* If the student clicks \"Start Free Trial\" button, they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course.\n",
    "* If the student clicks \"Access Course Materials\", they will be able to view the videos and take the quizzes for free, but they will not receive any bonuses, like coaching services or earning the certificate of the course.\n",
    "\n",
    "### Description of the Experiment\n",
    "\n",
    "* In the experiment, Udacity tested a change where if the student clicked \"Start Free Trial\" button, they were asked how much time they had available to devote to the course. \n",
    "* If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. \n",
    "* If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. \n",
    "* At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead.\n",
    "\n",
    "### Hypothesis Testing\n",
    "\n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough timeâ€”without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n",
    "\n",
    "### Unit of Diversion\n",
    "\n",
    "The unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page.\n",
    "\n",
    "## Experiment Design\n",
    "### Metric Choice\n",
    "\n",
    "The invariant metrics are the ones which shouldn't change across the experiment and the control group. These metrics work to perform a sanity check after running the experiment to test if there was any issue on the process.\n",
    "\n",
    "The evaluation metrics are those target metrics that you expect to change across groups and are relevant for the business goals. For each metric, it is defined a $D_{min}$ which marks the minimum change which is practically significant to the business. This figure is provided by Udacity for each of the metrics:\n",
    "\n",
    "#### Invariant Metrics (Sanity Check)\n",
    "\n",
    "For this case, the following metrics will be chosen as invariant metrics:\n",
    "\n",
    "* Number of cookies per course page by day. This metric has been chosen because in this case the number of cookies for each group should remain the same during the experiment. As cookies is our unit of diversion for this experiment, the sample size needs to be the same across both groups. It will be represented by $Cookies$ and it has a $D_{min} = 3,000$.\n",
    "  \n",
    "* Number of clicks in the 'Start Free Trial' button by day. As this click happens before the Free Trial Screener message appears, this metric shouldn't be impacted by the experiment. It should remain with no changes. It will be represented by $Clicks$ and it has a $D_{min} = 240$.\n",
    "  \n",
    "* Click-Through-Probability in the 'Start Free Trial' button by day. This metric is the relationship between the number of clicks on the 'Start Free Trial' button and the number of cookies on page. If these two metrics don't change, the CTP shouldn't change either. It will be represented by $\\frac{Clicks}{Cookies}$ and it has a $D_{min} = 0.01$.\n",
    "\n",
    "#### Evaluation Metrics\n",
    "\n",
    "The metrics that will be used as evaluation metrics are:\n",
    "\n",
    "* Gross Conversion. This metric is the relationship between the number of user IDs to complete the checkout and enroll the free trial divided by unique cookie clicks on the button. It will be represented by $\\frac{User IDs enrolled}{Clicks}$ and it has a $D_{min} = 0.01$.\n",
    "\n",
    "* Retention. This metric is the relationship between the number of user IDs to remain enrolled and make at least one payment divided by unique user IDs to complete the checkout. It will be represented by $\\frac{User IDs paid}{User IDs enrolled}$ and it has a $D_{min} = 0.01$.\n",
    "  \n",
    "* Net Conversion. This metric is the relationship between the number of user IDs to remain enrolled and make at least one payment divided by the number of unique cookie clicks on the button. It will be represented by $\\frac{User IDs paid}{Clicks}$ and it has a $D_{min} = 0.0075$.\n",
    "\n",
    "These three metrics are expected to change because they are measured after the Free Trial Screener message appears. Also, they are relevant for the business because they help to measure the low funnel performance and retention.\n",
    "\n",
    "### Measuring Standard Deviation\n",
    "\n",
    "Udacity provides the following rough estimates for these metrics, probably measured with a daily aggregation. This is the baseline for each of the metrics:\n",
    "\n",
    "* Unique cookies to view course overview page per day: 40,000\n",
    "* Unique cookies to click \"Start free trial\" per day: 3,200\n",
    "* Enrollments per day: 660\n",
    "* Click-through-probability on \"Start free trial\": 0.08\n",
    "* Probability of enrolling, given click (Gross Conversion): 0.20625\n",
    "* Probability of payment, given enroll (Retention): 0.53\n",
    "* Probability of payment, given click (Net Conversion): 0.1093125\n",
    "\n",
    "Now, we will need to calculate the standard deviation for each of the evaluation metrics. This step is very important to test if a metric has a great variability or it is more robust. On one hand, the most variant a metric is, the harder is to get significant results. In the other hand, if the metric is too robust, it is possible it's too insensitive to capture the statistically significant change. \n",
    "\n",
    "Udacity assumes a sample size of 5,000 cookies visiting the course overview page per day. As the previous data is based on baseline numbers, we will need to readjust the metrics to a sample size of 5,000 cookies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the baseline estimates\n",
    "baseline = {\"Total Cookies\":40000, \"Total Clicks\":3200, \"Total Enrollments\":660, \"CTP\":0.08, \"Gross Conversion\":0.20625, \"Retention\":0.53, \"Net Conversion\":0.1093125}\n",
    "\n",
    "# Creating a copy of baseline to add the adjustments\n",
    "sample_adjusted = baseline\n",
    "\n",
    "# Defining the samples\n",
    "n = 40000\n",
    "n_adjusted = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total Cookies': 5000,\n",
       " 'Total Clicks': 400.0,\n",
       " 'Total Enrollments': 82.5,\n",
       " 'CTP': 0.08,\n",
       " 'Gross Conversion': 0.20625,\n",
       " 'Retention': 0.53,\n",
       " 'Net Conversion': 0.1093125}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the estimates from a sample size of 40,000 to 5,000\n",
    "\n",
    "sample_adjusted[\"Total Cookies\"] = 5000\n",
    "sample_adjusted[\"Total Clicks\"] = (n_adjusted * baseline[\"Total Clicks\"] / n)\n",
    "sample_adjusted[\"Total Enrollments\"] = (n_adjusted * baseline[\"Total Enrollments\"] / n)\n",
    "sample_adjusted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our evaluations metrics are probabilities, we can assume all of them have a binomial distribution (or normal, as we have enough data samples). Now, let's calculate the standard deviation based on this with the following formula:\n",
    "\n",
    "$$SD = \\sqrt{\\frac{p'(1-p')}{N}}$$\n",
    "\n",
    "We can do this assumption for the Gross Conversion and the Net Conversion because the unit of diversion is the same that the unit of analysis (metric placed on the denominator). In this case, the unit of diversion is the cookie, as well as the unit of analysis (number of cookies who clicked). We can expect the analytical estimates to be accurate.\n",
    "\n",
    "However, the Retention metric doesn't have the same unit of analysis and unit of diversion. In this case, the unit of diversion is the cookie but the unit of analysis is the user ID. For this reason, the analytical estimates might not match the empirical estimates and it will be worth it to calculate it empirically too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to calculate the standard deviation\n",
    "def sd(p, n):\n",
    "    dic = {}\n",
    "    dic[\"sd\"] = round(np.sqrt((p*(1-p))/n), 4)\n",
    "    return dic['sd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0202\n",
      "0.0549\n",
      "0.0156\n"
     ]
    }
   ],
   "source": [
    "# Let's create three new dictionaries for each metric\n",
    "gross_conversion = {}\n",
    "retention = {}\n",
    "net_conversion = {}\n",
    "\n",
    "# Adding the Dmin data to each dictionary\n",
    "gross_conversion[\"d_min\"] = 0.01\n",
    "retention[\"d_min\"] = 0.01\n",
    "net_conversion[\"d_min\"] = 0.0075\n",
    "\n",
    "# Calculating p and n for each metric\n",
    "gross_conversion[\"p\"] = sample_adjusted[\"Gross Conversion\"]\n",
    "gross_conversion[\"n\"] = sample_adjusted[\"Total Clicks\"]\n",
    "\n",
    "retention[\"p\"] = sample_adjusted[\"Retention\"]\n",
    "retention[\"n\"] = sample_adjusted[\"Total Enrollments\"]\n",
    "\n",
    "net_conversion[\"p\"] = sample_adjusted[\"Net Conversion\"]\n",
    "net_conversion[\"n\"] = sample_adjusted[\"Total Clicks\"]\n",
    "\n",
    "# Using the function created to get the standard deviation\n",
    "print(sd(gross_conversion[\"p\"], gross_conversion['n']))\n",
    "print(sd(retention[\"p\"], retention['n']))\n",
    "print(sd(net_conversion[\"p\"], net_conversion['n']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizing\n",
    "#### Number of Samples vs. Power\n",
    "\n",
    "First of all, we are going to use the formula Evan Miller used on his online calculator to calculate the sample size:\n",
    "\n",
    "$$n = \\frac{Z_{1-\\frac{\\alpha}{2}}Â·sd_{1}+Z_{1-\\beta}Â·sd_{2}}{d^2}$$\n",
    "\n",
    "$$sd_{1} = \\sqrt{2p(1-p)}$$\n",
    "$$sd_{2} = \\sqrt{p(1-p)+(p+d)(1-p-d)}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $p_{1}$ is the baseline conversion rate.\n",
    "* $\\delta$ is the detectable change.\n",
    "* $\\alpha$ is the significance level.\n",
    "* $\\beta$ is the statistical power or practice significance.\n",
    "* $Z_{\\frac{\\alpha}{2}}$ means the z-score from the z table that corresponds to $\\frac{\\alpha}{2}$\n",
    "* $Z_{\\beta}$ means the z-score from the z table that corresponds to $\\beta$\n",
    "\n",
    "During the whole experiment, $\\alpha = 0.05$ and $1-\\beta = 0.20$. The z-score for each of them are $Z_{\\frac{0.05}{2}} = -1.959963985$ and $Z_{\\beta} = -0.841621234$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the sample size\n",
    "def sample_size(p, delta):\n",
    "    if p > 0.5:\n",
    "        p = 1.0 - p\n",
    "    \n",
    "    z_a = 1.959963985\n",
    "    z_b = 0.841621234\n",
    "\n",
    "    sd1 = np.sqrt(2 * p * (1.0 - p))\n",
    "    sd2 = np.sqrt(p * (1.0 - p) + (p + delta) * (1.0 - p - delta))\n",
    "\n",
    "    return round((z_a * sd1 + z_b * sd2) * (z_a * sd1 + z_b * sd2) / (delta * delta), 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gross Conversion\n",
    "\n",
    "For Gross Conversion, we will need at least 25,835 cookies who click in the Free Trial button per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25835.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_conversion['sample_size'] = sample_size(gross_conversion['p'], gross_conversion['d_min'])\n",
    "gross_conversion['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to estimate the number of pageviews needed to achieve those 25,835 cookies per group. To do so, we need to calculate the ratio between clicks and pageviews: $400/5000 = 0.08$. Now, let's divide the sample size we got between this result and multiply it by two, as we have two groups in the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645875.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_conversion['sample_size'] = (gross_conversion['sample_size']/0.08)*2\n",
    "gross_conversion['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would need in total 645,875 pageviews in total counting both groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retention\n",
    "\n",
    "Regarding retention, we will need at least 39,087 users who enrolled per group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39115.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retention['sample_size'] = sample_size(retention['p'], retention['d_min'])\n",
    "retention['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we divide this result by 0.08 to know how many users need to click on the 'Start Free Trial' button and then how many cookies viewed a course overview page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4741212.121212121"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retention['sample_size'] = ((retention['sample_size']/0.08)/gross_conversion['p'])*2\n",
    "retention['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we will need 4,74 million pageviews. However, this number is quite high, as Udacity attracts 40,000 cookies per day. The experiment would need to last 120 days to gather the necessary sample. For these reasons, we drop this metric from the experiment.\n",
    "\n",
    "##### Net Conversion\n",
    "\n",
    "For net conversion, we will need at least 27,413 users who click per group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27413.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_conversion['sample_size'] = sample_size(net_conversion['p'], net_conversion['d_min'])\n",
    "net_conversion['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to calculate how many pageviews we will need by dividing between 0.08. This way, we will need 685,325 pageviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685325.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_conversion['sample_size'] = ((net_conversion['sample_size']/0.08))*2\n",
    "net_conversion['sample_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this number of pageviews is bigger than the one needed for the gross conversion, this is going to be our sample size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration vs. Exposure\n",
    "\n",
    "As we said, we will need 685,325 cookies who viewed the course overview page. If we take the 100% of the traffic, the experiment will take 18 days. However, we prefer the experiment to take one month, so we collect four different weeks of data. This way, we'll be able to see if there is important variations between workdays and weekdays. After taking this decision, the experiment will last 28 days, collecting 24,476 cookies per day. This is around 55% of daily traffic.\n",
    "\n",
    "## Experiment Analysis\n",
    "\n",
    "Now, let's analyze the data once the experiment has been run. First of all, we will create two different dataframes, one for the control group and other for the experiment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0  Sat, Oct 11       7723     687        134.0      70.0\n",
       "1  Sun, Oct 12       9102     779        147.0      70.0\n",
       "2  Mon, Oct 13      10511     909        167.0      95.0\n",
       "3  Tue, Oct 14       9871     836        156.0     105.0\n",
       "4  Wed, Oct 15      10014     837        163.0      64.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = pd.read_excel(\"final_project_results.xlsx\", sheet_name = 'Control')\n",
    "exp = pd.read_excel(\"final_project_results.xlsx\", sheet_name = 'Experiment')\n",
    "con.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "\n",
    "The first step before analyzing the results is performing a sanity check in the invariant metrics. This will help us to define if the experiment was ran as expected. For each of our invariant metrics, we will check if they pass the test or not:\n",
    "\n",
    "* Number of cookies per course page.\n",
    "  \n",
    "* Number of clicks in the 'Start Free Trial' button.\n",
    "  \n",
    "* Click-Through-Probability in the 'Start Free Trial' button.\n",
    "\n",
    "#### Sanity Check for Counts\n",
    "\n",
    "For a count, we should calculate a confidence interval around the fraction of events you expect to be assigned to the control group, and the observed value should be the actual fraction that was assigned to the control group. \n",
    "\n",
    "##### Number of Cookies per Course Page\n",
    "\n",
    "Let's take a look to the total pageviews for each group. If we calculate the total number of pageviews per group, we can see the difference is quite low between groups. However, is this within what we expected? We need to verify that this difference is not statistically significant and was randomly \n",
    "\n",
    "As this invariant metric follows a binomial distribution, we can build a binomial confidence interval. The total sample size here is about 690,203 cookies, which is definitively enough to assume a normal distribution in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pagesviews for control group: 345543 \n",
      "Total number of pageviews for experiment group: 344660\n",
      "The size of the sample is 690203\n"
     ]
    }
   ],
   "source": [
    "# Summing the total number of pageviews for each group\n",
    "con_pages = con['Pageviews'].sum()\n",
    "exp_pages = exp['Pageviews'].sum()\n",
    "print(f\"Total number of pagesviews for control group: {con_pages} \\nTotal number of pageviews for experiment group: {exp_pages}\")\n",
    "\n",
    "# Summing the total sample size\n",
    "total_pages = con_pages + exp_pages\n",
    "print(f\"The size of the sample is {total_pages}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will compute the standard deviation of a binomial distribution with probability 0.5 of success, which I'll assign as control group. \n",
    "\n",
    "Then, we'll multiply the standard deviation by the z-score to get the margin of error. The z-score used in the margin of error for a 95% of confidence interval is 1.96. This can be checked in the z-score tables availables on the Internet.\n",
    "\n",
    "After that, we'll compute a confidence interval around 0.5. If the experiment is set up properly, it's very likely that this observed fraction of successes or cookies in the control group will fall within this confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error for pageviews is 0.0006\n",
      "The margin of error for pageviews is 0.0012\n",
      "The upper confidence interval for pageviews is 0.5012 and the lower confidence interval is 0.4988\n"
     ]
    }
   ],
   "source": [
    "# Calculating the standard error for a normal distribution\n",
    "se_pages = round(np.sqrt((0.5*0.5)/total_pages), 4)\n",
    "print(f\"The standard error for pageviews is {se_pages}\")\n",
    "\n",
    "# Calculating the margin of error\n",
    "me_pages = round(se_pages * 1.96, 4)\n",
    "print(f\"The margin of error for pageviews is {me_pages}\")\n",
    "\n",
    "# Calculating the confidence interval\n",
    "print(f\"The upper confidence interval for pageviews is {0.5+me_pages} and the lower confidence interval is {0.5-me_pages}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the portion of pageviews for the control group to see if it's inside the interval or not. As we can see, 0.5006 is within the confidence interval. This means the difference between the groups is expected, so this metric passes the sanity check correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of pageviews from the total for the control group is 0.5006\n"
     ]
    }
   ],
   "source": [
    "# Calculating the fraction of the control group\n",
    "p_hat_pages = round(con_pages/total_pages, 4)\n",
    "print(f\"The fraction of pageviews from the total for the control group is {p_hat_pages}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Clicks in 'Start Free Trial' Button\n",
    "\n",
    "Let's follow the same approach for the total number of clicks on the 'Start Free Trial' button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of clicks for control group: 28378 \n",
      "Total number of pageviews for experiment group: 28325\n",
      "The size of the sample is 56703\n"
     ]
    }
   ],
   "source": [
    "# Summing the total number of pageviews for each group\n",
    "con_clicks = con['Clicks'].sum()\n",
    "exp_clicks = exp['Clicks'].sum()\n",
    "print(f\"Total number of clicks for control group: {con_clicks} \\nTotal number of pageviews for experiment group: {exp_clicks}\")\n",
    "\n",
    "# Summing the total sample size\n",
    "total_clicks = con_clicks + exp_clicks\n",
    "print(f\"The size of the sample is {total_clicks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error for clicks is 0.0021\n",
      "The margin of error for clicks is 0.0041\n",
      "The upper confidence interval for clicks is 0.5041 and the lower confidence interval is 0.4959\n"
     ]
    }
   ],
   "source": [
    "# Calculating the standard error for a normal distribution\n",
    "se_clicks = round(np.sqrt((0.5*0.5)/total_clicks), 4)\n",
    "print(f\"The standard error for clicks is {se_clicks}\")\n",
    "\n",
    "# Calculating the margin of error\n",
    "me_clicks = round(se_clicks * 1.96, 4)\n",
    "print(f\"The margin of error for clicks is {me_clicks}\")\n",
    "\n",
    "# Calculating the confidence interval\n",
    "print(f\"The upper confidence interval for clicks is {0.5+me_clicks} and the lower confidence interval is {0.5-me_clicks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of clicks from the total for the control group is 0.5005\n"
     ]
    }
   ],
   "source": [
    "# Calculating the fraction of the control group\n",
    "p_hat_clicks = round(con_clicks/total_clicks, 4)\n",
    "print(f\"The fraction of clicks from the total for the control group is {p_hat_clicks}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check for Probabilities & Rates\n",
    "\n",
    "For any other type of metric, we should construct a confidence interval for a difference in proportions, then check whether the difference between group values falls within that confidence level.\n",
    "\n",
    "##### Click-Through-Probability in 'Start Free Trial' Button\n",
    "\n",
    "for the CTP, we want to make sure the proportion of clicks given a pageview is similar in both groups. We'll need to calculate the confidence interval for the difference. We'll start by calculating the pooled probability, that is the total number of clicks in both groups divided by the total number of users.\n",
    "\n",
    "$$p'_{pooled} = \\frac{clicks_{con}+clicks_{exp}}{pages_{con}+pages_{exp}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pooled probability is 0.0822\n"
     ]
    }
   ],
   "source": [
    "# Calculating the pooled probability\n",
    "p_pool = round((total_clicks) / (total_pages), 4)\n",
    "print(f\"The pooled probability is {p_pool}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll calculate the standard error using the following formula:\n",
    "\n",
    "$$SE_{pool} = \\sqrt{p'_{pool}Â·(1-p'_{pool})Â·(\\frac{1}{N_{con}}+\\frac{1}{N_{exp}})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error is 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Calculating the standard error\n",
    "se_pool = round(np.sqrt(p_pool*(1-p_pool)*(1/con_pages+1/exp_pages)),4)\n",
    "print(f\"The standard error is {se_pool}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined the estimated difference as the experimental probability minus the control probability. Let's calculate this difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference for the CTP is 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Calculating the CTP for control and experiment group\n",
    "con_ctp = con_clicks/con_pages\n",
    "exp_ctp = exp_clicks/exp_pages\n",
    "\n",
    "# Calculating difference for the CTP\n",
    "d_hat=round(exp_ctp-con_ctp,4)\n",
    "print(f\"The difference for the CTP is {d_hat}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the margin of error and the confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The margin of error is is 0.0007\n",
      "The upper confidence interval for CTP is 0.0015 and the lower confidence interval is -0.0013\n"
     ]
    }
   ],
   "source": [
    "# Calculating the margin of error\n",
    "me_ctp = round(se_pool * 1.96, 4)\n",
    "print(f\"The margin of error is is {se_pool}\")\n",
    "\n",
    "# Calculating the confidence interval\n",
    "print(f\"The upper confidence interval for CTP is {d_hat+me_ctp} and the lower confidence interval is {d_hat-me_ctp}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 0.0001 is inside our confidence interval, we can say this change in the CTP is not significant and random. So, this metric passes the test too!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "#### Effect Size Tests\n",
    "\n",
    "For each of your evaluation metrics, give a 95% confidence interval around the difference between the experiment and control groups. Indicate whether each metric is statistically and practically significant. (These should be the answers from the \"Effect Size Tests\" quiz.)\n",
    "\n",
    "#### Sign Tests\n",
    "\n",
    "For each of your evaluation metrics, do a sign test using the day-by-day data, and report the p-value of the sign test and whether the result is statistically significant. (These should be the answers from the \"Sign Tests\" quiz.)\n",
    "\n",
    "#### Summary\n",
    "\n",
    "State whether you used the Bonferroni correction, and explain why or why not. If there are any discrepancies between the effect size hypothesis tests and the sign tests, describe the discrepancy and why you think it arose.\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "Make a recommendation and briefly describe your reasoning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow-Up Experiment\n",
    "\n",
    "Give a high-level description of the follow up experiment you would run, what your hypothesis would be, what metrics you would want to measure, what your unit of diversion would be, and your reasoning for these choices.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ace5384e8512bec205467adaaa03d1a59280dc6777c0f016ce91eb37065280f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
